---
title: "Section 2: Association between iron status and breast cancer risk for women who are premenopausal at baseline (case-cohort analysis)"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: true
    includes:
      in_header: header.tex 
  html_document:
    theme: united
    toc: yes
linkcolor: red
urlcolor: red
citecolor: red
geometry: margin=1.5cm
editor_options:
  chunk_output_type: console
always_allow_html: true
---


```{r , include=FALSE}
knitr::opts_chunk$set(echo = T, 
                      results = 'markup',
                      warning = F,
                      fig.width=10,
                      fig.height=8)

```


```{r, include=F}
# bring in packages
require(knitr)
require(data.table)
require(tableone)
require(kableExtra)
require(rowr)
require(survival)
require(stargazer)
require(splines)
require(ggplot2)
require(survminer)
require(dplyr)
require(reshape2)
require(ggpubr)
require(tools)
require(Hmisc)
require(janitor)
require(foreign)
require(haven)

require(survminer)

require(broom)

```


```{r}

# source: section1.Rmd
load(file="../sections/updated-data-iron.RData") # df3 is the iron subset

df=data.frame(df3[df3$subcohort %in% c(0,1),])
dim(df)
with(df[df$SE_RACE15==5,], table(subcohort, event))

table(as_factor(df$SE_RACE15))
table(as_factor(df$SE_RACE_ETH))

summary(df$c.age)
```


```{r}

# get information on menopause status by subcohort

# subset to post-menopausal at baseline
table(df$menop.status.f)
table(df$menop.status)
prop.table(table(df$menop.status.f)) # 67 % are post menopausal at baseline

counts.menop = with(df, addmargins(table(subcohort, menop.status.f))); counts.menop
props.menop = with(df, prop.table(addmargins(table(menop.status.f, subcohort),2))) ; props.menop

save(counts.menop, props.menop, file="menop-counts.RData")
```


```{r}
# How many non-subcohort members are excluded from premenopausal data given they 
# experience menopause before the event
# Assume they are still pre-menopausal at baseline.

df$fu.meno.age.rev = with(df, ifelse( is.na(fu.meno.age)==T & menop.status==1, baseline.age, # if a person is missing menopause age but postmenopausal at baseline then put age at menopause as entry age.
                                    ifelse(is.na(fu.meno.age)==T & menop.status==0, 99, fu.meno.age ))) # if there is no age at menopause and they are premenopausal at baseline then put 99 so they never experience menopause as a time-dept measure (no person is recorded above age 98 so put age 99)
table(df$fu.meno.age.rev)

with(df, table(subcohort, event))
df$c.age.alt = with(df, ifelse(menop.status==1, c.age, # if a person is postmenop at baseline then keep original censoring age
                               ifelse(menop.status==0 & c.age>fu.meno.age.rev & fu.meno.age.rev>start.age, fu.meno.age.rev, # premenopausal at baseline and censoring age after menopause age then make censoring age the age at menopause
                                      ifelse(fu.meno.age.rev<=start.age, NA, c.age))))

df$omit.case = with(df, ifelse(c.age.alt < c.age, 1, 0)) # if the censoring age based on menopause status for those who are premenopausal at baseline is less than the censoring age then remove them from analysis (if they are not in subcohort)

table(df$omit.case) # 344 out of 5582 are excluded from analysis
with(df, table(subcohort, omit.case)) # 29/(291+2413=2704)=11% of cases were excluded from analysis

with(df[df$menop.status==0,], table(subcohort, omit.case)) # 291/(509+291 = 800) = 36% of non-subcohort were excluded from analysis of premenopausal women

with(df[df$menop.status==0,], table(subcohort, omit.case))
sum(with(df[df$menop.status==0,], table(subcohort, omit.case)))  

# how many non-subcohort members are excluded from premenopausal data given they 
# experience menopause before the event
# should I assume they are still pre-menopausal at baseline?

df$event.alt = with(df, ifelse(c.age.alt < c.age & subcohort==0, NA, # if alternative censor age based on menopause age is less than original censor age then no event for non-subcohort people
                               ifelse(c.age.alt<c.age & subcohort==1, 0, event))) # if people have their event following menopause then they are changed to a non-event, otherwise event.
summary(df$event.alt)
```

```{r}

# check data for person who experiences menopause before event in subcohort and no event
head(df[which(df$c.age.alt < df$c.age & df$subcohort==1), c("PSID", "menop.status", 
                                                            "fu.meno.age", 'fu.meno.age.rev', "subcohort",
                                                            "start.age", "c.age",
                                                            "c.age.alt", "event", "event.alt")])

# check data for person who experiences menopause before event in subcohort and event
head(df[which(df$c.age.alt < df$c.age & df$subcohort==1 & df$event==1), c("PSID", "menop.status", 
                                                            "fu.meno.age", 'fu.meno.age.rev', "subcohort",
                                                            "start.age", "c.age",
                                                            "c.age.alt", "event", "event.alt")])

# check data for person who experiences menopause before event in NON-subcohort
head(df[which(df$c.age.alt < df$c.age & df$subcohort==0), c("PSID", "menop.status", 
                                                            "fu.meno.age", 'fu.meno.age.rev', "subcohort",
                                                            "start.age", "c.age",
                                                            "c.age.alt", "event", "event.alt")])

# check data for person who experiences menopause before event in NON-subcohort
head(df[which(df$c.age.alt < df$c.age & df$subcohort==0), c("PSID", "menop.status", 
                                                            "fu.meno.age", 'fu.meno.age.rev', "subcohort",
                                                            "start.age", "c.age",
                                                            "c.age.alt", "event", "event.alt")])

```


```{r}

# handle data for survival analysis
df = within(df, {

  fe.log = log(UMN_Iron_Baseline_FE)
  fertn.log = log(UMN_Iron_Baseline_FERTN)
  fesat.log = log(UMN_Iron_Baseline_FESAT)
  tibc.log = log(UMN_Iron_Baseline_TIBC)
  uibc.log = log(UMN_Iron_Baseline_UIBC)
    
  fe.scale = scale(log(UMN_Iron_Baseline_FE), scale=F)
  fertn.scale = scale(log(UMN_Iron_Baseline_FERTN), scale=F)
  fesat.scale = scale(log(UMN_Iron_Baseline_FESAT), scale=F)
  tibc.scale = scale(log(UMN_Iron_Baseline_TIBC), scale=F)
  uibc.scale = scale(log(UMN_Iron_Baseline_UIBC), scale=F)
})

summary(df$futime)
summary(df$c.age)
summary(df$FU_BCInvD_EOFAge)
summary(df$FU_BCInvD_EOFAgeExact)
sapply(df[c('alc.f3', 'educ.f2', 'ever.hrt.f', 'birth.control.f',
                     'age.menarche', 'age.firstbirth.cat')], summary)
                     
outcome.vars = c("fe", "fertn", "fesat")

# time-dept menopause ==============================

summary(df$fu.meno.age) # 892 missing
df$miss.meno.age = with(df, is.na(df$fu.meno.age))
with(df, table(miss.meno.age, menop.status)) # 27 people are post-menopausal at baseline but no age at menopause. Put age at menopause at baseline age.

df$miss.meno.age.rev = with(df, is.na(df$fu.meno.age.rev))
with(df, table(miss.meno.age.rev, menop.status)) # check

dim(df)

```


```{r}

df.tot = df[df$subcohort==1,] # use this data frame for quartile calcs. has subcohort for both pre- and postmenopause groups.
dim(df.tot) # 3169

df = df[which(df$menop.status==0),]
dim(df) # 1938

```


```{r}
# PCA code

# Source: https://raw.githubusercontent.com/WinVector/Examples/master/PCR/XonlyPCA.Rmd
extractProjection <- function(ndim,princ) {
  # pull off the rotation.  
  proj <- princ$rotation[,1:ndim] 
  # sign was arbitrary, so flip in convenient form
  for(i in seq_len(ndim)) {
    si <- sign(mean(proj[,i]))
    if(si!=0) {
      proj[,i] <- proj[,i]*si
    }
  }
  proj
}

```

```{r}
# get first PC

iron.vars = c("fe", 'fesat', "fertn")
iron.log.vars = c("fe.log", "fesat.log", "fertn.log")
head(df)

dim(df.tot)
# Source: http://www.win-vector.com/blog/2016/05/pcr_part1_xonly/
cc = df[complete.cases(df[iron.log.vars]),]$PSID
head(cc)
cc.tot = df.tot[complete.cases(df.tot[iron.log.vars]),]$PSID
length(cc.tot)

m.df = as.matrix(df[which(df$PSID %in% cc), iron.log.vars])# use complete cases
head(m.df)
m.df.tot = as.matrix(df.tot[which(df.tot$PSID %in% cc.tot), iron.log.vars])# use complete cases

pca.log = prcomp(m.df, center=T, scale.=T) # scale variables because units are not same across 3 measures.
pca.log.tot = prcomp(m.df.tot, center=T, scale.=T) # scale variables because units are not same across 3 measures.

# signs are arbitrary on PCA, so instead of calling predict we pull out
# (and alter) the projection by hand

projectedTrainIdeal <-
  as.data.frame(scale(m.df) %*% extractProjection(3,pca.log),
                                 stringsAsFactors = FALSE)
dim(projectedTrainIdeal)
dim(m.df)

projectedTrainIdeal.tot <-
  as.data.frame(scale(m.df.tot) %*% extractProjection(3,pca.log.tot),
                                 stringsAsFactors = FALSE)

df.pc = cbind(projectedTrainIdeal, df[which(df$PSID %in% cc),])
with(df.pc, cor(PC1, fe))

df.pc.tot = cbind(projectedTrainIdeal.tot, df.tot[which(df.tot$PSID %in% cc.tot),])
with(df.pc.tot, cor(PC1, fe))
dim(df.pc.tot)

summary(df.pc$fesat)
hist(df.pc$fesat)
```




```{r}

# function to output HR with 95% ci =========================
get.ci = function(df){
  
  colnames(df)[which(colnames(df) %in% c("SE"))] = "se.coef"
  colnames(df)[which(colnames(df) %in% c("p"))] = "p.value"
  colnames(df)[which(colnames(df) %in% c("Value"))] = "coef"

  # source: https://stackoverflow.com/questions/50118394/selecting-and-colouring-single-table-cells-with-kableextra-in-r-markdown-cell-sp
  
   with(data.frame(df),  ifelse(p.value<0.05/16,
                                paste0("\\textbf{",
                                       formatC(round(exp(coef),2), format="f", flag='0', digits=2),
                                       " (",
                                      formatC(round(exp(coef-1.96*se.coef),2), format="f", digits=2),
                                      ", ",
                                      formatC(round(exp(coef+1.96*se.coef),2), format="f", digits=2),
                                      ")}"),
        paste0(formatC(round(exp(coef),2), format="f", flag='0', digits=2),
                                  " (",
                                  formatC(round(exp(coef-1.96*se.coef),2), format="f", digits=2),
                                  ", ",
                                  formatC(round(exp(coef+1.96*se.coef),2), format="f", digits=2),
                                  ")")))
  }

```

```{r, eval=T, include=F}
# double checking numbers

str(df.pc)
test = df.pc

get.info = function(var){
  # var="fertn.log"
  test$iron.cov = test[,var]
  qrts = quantile(test$iron.cov, c(0, 0.25, 0.5, 0.75, 1), na.rm=T)
  qrts

  test$cutq = cut(test$iron.cov, qrts, include.lowest = T, dig.lab=4)

  # source: https://stackoverflow.com/questions/24576515/relative-frequencies-proportions-with-dplyr
  
  test2 = test %>%
    group_by(cutq, event) %>%
    summarise(n = n()) %>%
    mutate(freq = n / sum(n))
  test2
  
  dat.wide = dcast(test2, event ~ cutq, value.var="n")
  dat.wide
  
  dat.wide = dcast(test2[test2$event==1,], event ~ cutq, value.var="freq")
  dat.wide
}

get.info("fe")
get.info("fertn.log")
get.info("fesat")

outcome.vars = c("fe", "fertn.log", "fesat", 'PC1')


# look at km to double check dip at lower values of fertn.log
# no weighting so biased
# ====================================================================

summary(df.pc$fertn.log)
qrts = quantile(df.pc$fertn.log, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use sample for quartile calcs
df.pc$fertn.cutq = cut(df.pc$fertn.log, qrts, include.lowest = T, dig.lab=4)
summary(df.pc$fertn.cutq)

# Source: https://github.com/kassambara/survminer/issues/67
fit = survfit(Surv(start.age, c.age.alt, event.alt) ~ fertn.cutq ,
             data=df.pc)

ggsurvplot(fit,  palette = "Dark2", 
           censor = FALSE,
           xlim=c(45,60))

# now check for transferrin saturation

# look at km double check fertn.log
# ====================================================================

summary(df.pc$fesat)
qrts = quantile(df.pc$fesat, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use sample for quartile calcs
df.pc$fesat.qrt = cut(df.pc$fesat, qrts, include.lowest = T, dig.lab=4)
summary(df.pc$fesat.qrt)

vars.include = c("start.age", "c.age.alt",
                "event.alt", "fesat.qrt",
                "subcohort")

# Source: https://github.com/kassambara/survminer/issues/67
fit = survfit(Surv(start.age, c.age.alt, event.alt) ~ fesat.qrt ,
             data=df.pc[complete.cases(df.pc[vars.include]) & df.pc$start.age>45,])

ggsurvplot(fit,  palette = "Dark2", 
           censor =T,
           xlim=c(45,60))

# fertn
# ==========================================
summary(df.pc$fertn)
qrts = quantile(df.pc$fertn, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use sample for quartile calcs
df.pc$fertn.qrt = cut(df.pc$fertn, qrts, include.lowest = T, dig.lab=4)
summary(df.pc$fertn.qrt)

# now check for fe
# ====================================================================

summary(df.pc$fe)
qrts = quantile(df.pc$fe, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use sample for quartile calcs
df.pc$fe.qrt = cut(df.pc$fe, qrts, include.lowest = T, dig.lab=4)
summary(df.pc$fe.qrt)

vars.include = c("start.age", "c.age.alt",
                "event.alt", "fesat.qrt",
                "subcohort")

# Source: https://github.com/kassambara/survminer/issues/67
fit = survfit(Surv(start.age, c.age.alt, event.alt) ~ fe.qrt ,
             data=df.pc[complete.cases(df.pc[vars.include]) & df.pc$start.age>45,])

ggsurvplot(fit,  palette = "Dark2", 
           censor =T,
           xlim=c(45,60))

# now double check the case cohort analysis

summary(df.pc[vars.include])

fit.cch = cch(Surv(start.age, c.age.alt, event.alt) ~ fesat.qrt, # + cluster(HH_PSID) # NOTE: clustering does not work
             data=df.pc[complete.cases(df.pc[vars.include]),],
             subcoh = ~subcohort,
             id = ~ PSID,
             cohort.size=50884)

tidy(fit.cch)

# make quartiles for pc
summary(df.pc$PC1)
qrts = quantile(df.pc$PC1, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use sample for quartile calcs
df.pc$pc1.qrt = cut(df.pc$PC1, qrts, include.lowest = T, dig.lab=4)
summary(df.pc$pc1.qrt)
```


```{r}
# export data for section4-cch-pre.Rmd and section5-cch-pre.Rmd
save(df.pc, file="data-pre.RData")
```


```{r}

# make a function of the previous analyses repeating over covariates.

get.coefs = function(var.fe, n.size=50884) {

# var.fe = "fertn" ; n.size=50884 # debug
# var.fe = "fertn.log" ; n.size=50884 # debug
# var.fe = "PC1"; n.size=50884 # debug
# var.fe = "fesat"; n.size=50884 # debug

df1=df.pc; dim(df.pc)
df.tot = df.pc.tot

# designate the iron covariate  
df1$iron.cov = df1[,var.fe] # source: https://stackoverflow.com/questions/2641653/pass-a-data-frame-column-name-to-a-function


df1=df1[!(is.na(df1$iron.cov)),] # need to remove missing for cch to work
dim(df1)
summary(df1$iron.cov)


# get untransformed values if log transform ferritin
if(var.fe=="fertn.log") {
 qrts = quantile(df1$fertn.log, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use sample for quartile calcs
 qrts2 = quantile(df1$fertn, c(0, 0.25, 0.5, 0.75, 1), na.rm=T)
  
  #qrts = quantile(log(df.tot$fertn), c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use total subcohort for quartile cutpoints
  #qrts2 = quantile(df.tot$fertn, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # use total subcohort for quartile cutpoints

  df1$fe.cutq = cut(df1$fertn.log, qrts, include.lowest = T, dig.lab=4)
  df1$fe.cutq2 = cut(df1$fertn, qrts2, include.lowest = T, dig.lab=4)
  
  table(is.na(df1$fe.cutq)); table(df1$fe.cutq)
  table(is.na(df1$fe.cutq2)); table(df1$fe.cutq2)
  
  dt.extra = data.table(df1) # use whole subset of sample (for premenopausal women)
  #dt.extra = data.table(df1[df1$subcohort==0,]) # use subcohort for quartile calcs
  #dt.extra = data.table(df.tot) # use total subchort for quartile calcs
  setkey(dt.extra, fe.cutq2)
  medians =  dt.extra[,list(median=median(fertn, na.rm=T)), by=fe.cutq2] # get medians in interval from the analysis data set
  medians = data.frame(medians[complete.cases(medians)])
  
  cell.ct = dt.extra[,list(count=.N), by=fe.cutq2]
  cell.ct = data.frame(cell.ct[complete.cases(cell.ct),])
  
  cell.ct2 = dt.extra[,list(count=.N), by=.(fe.cutq,subcohort.nocases) ]
  cell.ct2 = data.frame(cell.ct2[complete.cases(cell.ct2),])
} else {
  # get quartiles
  qrts = quantile(df1$iron.cov, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # quartiles based on analysis sample
  
  # designate the iron covariate for the total subcohort sample
  #df.tot$iron.cov = df.tot[,var.fe] # source: 
  #qrts = quantile(df.tot$iron.cov, c(0, 0.25, 0.5, 0.75, 1), na.rm=T) # quartiles based on entire subcohort sample (pre- and postmenopausal)
#qrts = quantile(df1$iron.cov, c(0, 0.1, 0.5, 0.9, 1), na.rm=T)
qrts

# make a variable with cut points based on quartiles above
df1$fe.cutq = cut(df1$iron.cov, qrts, include.lowest = T)#, dig.lab=4)

# what is the median within those intervals? =====================
dt = data.table(df1)
setkey(dt, fe.cutq)

medians = dt[,list(median=median(iron.cov, na.rm=T)), by=fe.cutq]
medians = data.frame(medians[complete.cases(medians)])

cell.ct = dt[,list(count=.N), by=fe.cutq]
cell.ct = data.frame(cell.ct[complete.cases(cell.ct),])

cell.ct2 = dt[,list(count=.N), by=.(fe.cutq,subcohort.nocases) ]
cell.ct2 = data.frame(cell.ct2[complete.cases(cell.ct2),])

}

medians
cell.ct

# 1) Cox ph with quartiles ==================================

# Modify censoring age and cut off at age at menopause
df1.sub = df1; dim(df1.sub)

vars. = c("start.age", "c.age", "c.age.alt", "event", "event.alt", "fe.cutq", "subcohort", "PSID",
                                         "fu.meno.age.rev")
df1.sub2 = df1.sub[complete.cases(df1.sub[,vars.]),]; dim(df1.sub2)

#head(test[test$c.age>test$fu.meno.age.rev, vars.])
#head(test[test$fu.meno.age.rev==99, vars.])

# Note: There must not be any censored observations outside the subcohort.
# no censor time lt the entry time
dim(df1.sub2) - dim(df1) # remove cases that have menopause before censoring -- not an event by age of menopause.
(dim(df1.sub2) - dim(df1))/dim(df1.sub2) # around 30% removed.

df1 = df1.sub2[!(df1.sub2$c.age<df1.sub2$start.age & df1.sub2$c.age.alt<=df1.sub2$start.age),]

# ==========================================
# run Cox models ==========================

cox.qrt = cch(Surv(start.age, c.age.alt, event.alt) ~ fe.cutq , # + cluster(HH_PSID) # NOTE: clustering does not work
             data=df1,
             subcoh = ~subcohort,
             id = ~ PSID,
             cohort.size=n.size)

cox.qrt
cox.qrt$n
cq = coef(summary(cox.qrt)); cq
coefs.qrts.p = round(cq[1,4],3); coefs.qrts.p

coefs.qrts = get.ci(cq)[1:3]; coefs.qrts
names(summary(cox.qrt))
n.event = summary(cox.qrt)$subcohort.size

tbl.qrt = kable(coef(summary(cox.qrt)), booktabs=T, 
                caption=paste0("iron.cov = ", var.fe)) %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = F)

# Note: need to switch to year-interval data for time-dept covariates. See section3.Rmd for explanation
# ============= beginning of data handling for year interval data ===================

# NOTE: you cannot use time-dependent variables with this approach to case-cohort data

# ============= end of data handling for year interval data ===================

# 2) Cox ph with quartiles, adjusted ========================================

# use baseline variables because we can't adjust for time-dept variables in out of the box case cohort analysis package.


sapply(df1[c("menop.age", "time.since.menop", "yrs.mens", "early.menop.45", "age.menarche", "parity")], summary) # check
sapply(df1[c("menop.age", "time.since.menop", "yrs.mens", "early.menop.45", "age.menarche", "parity")], class) # check

confounder.list.baseline = c('alc.f4',  'educ.f2', 'bmi', 'birth.control.f', "ever.hrt.f", 'smoke.f2',
                     'age.menarche', 'age.firstbirth.cat')
list.cc = c('alc.f4',  'educ.f2', 'bmi', 'birth.control.f', "ever.hrt.f", 'smoke.f2',
                     'age.menarche', 'age.firstbirth.cat')


(dim(df1) - dim(df1[complete.cases(df1[list.cc]),])) # people are left out with complete case analysis. 
(dim(df1) - dim(df1[complete.cases(df1[list.cc]),]))/dim(df1)[1] # proportion

form.qrt.adj = as.formula(paste0("Surv(start.age, c.age.alt, event.alt) ~ ", 
                         paste0(c("fe.cutq",
                                  confounder.list.baseline), collapse = " + ")))

cox.qrt.adj= cch(form.qrt.adj,
                  data=df1[complete.cases(df1[list.cc]),], # take only complete cases
                  subcoh = ~subcohort,
                  id = ~PSID,
                  cohort.size = n.size)

cox.qrt.adj
cqa = coef(summary(cox.qrt.adj)); cqa

# output coef with 95% ci
coefs.qrts.adj = get.ci(cqa)[1:3]; coefs.qrts.adj

coefs.qrts.adj.p = round(cqa[1,4],3); coefs.qrts.adj.p

n.event.adj = summary(cox.qrt.adj)$nevent

tbl.qrt.adj = kable(coef(summary(cox.qrt.adj)), booktabs=T,
                    caption=paste0("iron.cov = ", var.fe))  %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = F)

# 3) Cox ph with continuous covariate ===========================

df1 = within(df1, 
             quartile.cov <- as.integer(cut(iron.cov, quantile(iron.cov, probs=0:4/4),
                                                             include.lowest=T)))
#hist(df1$quartile.cov)

# source: https://stackoverflow.com/questions/7508229/how-to-create-a-column-with-a-quartile-rank
cox.lin = cch(Surv(start.age, c.age.alt, event.alt) ~ quartile.cov,
             data=df1,
             subcoh = ~subcohort,
                  id = ~PSID,
                  cohort.size = n.size)

summary(df1$quartile.cov)
histogram(df1$quartile.cov)

cox.lin

# plot the linear values in naive data analysis without Prentice weighting ============
# NOTE: does confirm the lower level of risk at either end of iron

cox.linn = coxph(Surv(start.age, c.age.alt, event) ~ pspline(iron.cov, df=4),
             data=df1)
summary(cox.linn)
termplot(cox.linn, term=1, se=TRUE, col.term=1, col.se=1)

cc = coef(summary(cox.lin))

# output coef with 95% ci
coefs.c = get.ci(cc)[1]
coefs.c
coefs.c.p = formatC(round(cc[1,4],3), format="f", digits=3)

# output coef with 95% ci
coefs.lin = get.ci(cc)[1]
coefs.lin

tbl.lin = kable(coef(summary(cox.lin)), booktabs=T,
                caption=paste0("iron.cov = ", var.fe))  %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = F)


# 4) Cox ph with continuous covariate, adjusted =========================

form.lin.adj = as.formula(paste0("Surv(start.age, c.age.alt, event.alt) ~ ", 
                         paste0(c("quartile.cov",
                                  confounder.list.baseline), collapse = " + ")))

cox.lin.adj= cch(form.lin.adj,
                  data=df1[complete.cases(df1[list.cc]),], # take only complete cases
                  subcoh = ~subcohort,
                  id = ~PSID,
                  cohort.size = n.size)

cox.lin.adj
ca = coef(summary(cox.lin.adj))

# output coef with 95% ci
coefs.ca = get.ci(ca)[1]
coefs.ca
coefs.ca.p = formatC(round(ca[1,4],3), format="f", digits=3)

# output coef with 95% ci
coefs.lin.adj = get.ci(ca)[1]
coefs.lin.adj

tbl.lin.adj = kable(coef(summary(cox.lin.adj)), booktabs=T, 
                    caption=paste0("iron.cov = ", var.fe))  %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = F)

colnames(medians)[1]="fe.cutq" # fix for the log transformed analyses
colnames(cell.ct)[1]="fe.cutq"
colnames(cell.ct2)[1]="fe.cutq"

# make data frames of results
df.info.adj = data.frame(cov.fe = var.fe,
                      groups = c( "ref", levels(medians[,"fe.cutq"])[2:4], "cont"),
                      coef =   c( "ref", coefs.qrts.adj, coefs.lin.adj),
                      adj="Yes")

df.info.unadj = data.frame(cov.fe = var.fe,
                      groups = c("ref", levels(medians[,"fe.cutq"])[2:4], "cont"),
                      coef = c( "ref", coefs.qrts, coefs.lin), 
                      adj="No")

df.info.median = data.frame(cov.fe = var.fe,
                            groups =c("ref", levels(medians[,"fe.cutq"])[2:4], "cont"),
                            coef = if(var.fe == "PC1")
                              {c(formatC(round(medians[,"median"],1), format="f", digits=1),
                                 NA)} else
                                 {c(formatC(round(medians[,"median"],0), format="f", digits=0),
                                   NA)},
                      adj="Median")

df.info.ranges = data.frame(cov.fe = var.fe,
                            groups =c("ref", levels(medians[,"fe.cutq"])[2:4], "cont"),
                            coef = c(levels(medians[,"fe.cutq"])[1:4], NA),
#                        c(formatC(round(medians.orig[,"median"],1), format="f", digits=0),
#                               "NA"),
                      adj="Ranges")


df.info.ct = data.frame(cov.fe = var.fe,
                        groups =c("ref", levels(cell.ct[,"fe.cutq"])[2:4], "cont"),
                      
                        coef = c(formatC(round(cell.ct[,"count"],0), format="f", digits=0),NA),
                      adj="Counts")

df.info.ct2 = data.frame(cov.fe = var.fe,
                        groups = rep(c("ref", levels(cell.ct2[,"fe.cutq"])[2:4]),each=2),
                        coef = c(formatC(round(cell.ct2[1:4,"count"],0), format="f", digits=0),
                                 formatC(round(cell.ct2[5:8,"count"],0), format="f", digits=0)),
                        cases = c(cell.ct2$subcohort.nocases[1:4],
                                  cell.ct2$subcohort.nocases[5:8]),
                        adj="Counts")


df.info.median2 = df.info.median; df.info.median2$cases=NA
df.info.ranges2 = df.info.ranges; df.info.ranges2$cases=NA
df.info2 = rbind.data.frame(df.info.ct2,
                            df.info.median2,
                            df.info.ranges2)

df.info  = rbind.data.frame(df.info.median,
                            df.info.ct,
                            df.info.ranges,
                            df.info.adj,
                            df.info.unadj)  # data frame with summary statistics
df.info

# get info to plot histogram and quartiles
df1.hist = data.frame(iron.var = df1[,var.fe],
                      cov.fe = var.fe,
                      quart1 = qrts[2],
                      quart2 = qrts[3],
                      quart3 = qrts[4])


# put all this info into a list of objects to output from the function =====================

return(list(df.info, tbl.qrt, tbl.qrt.adj, tbl.lin, tbl.lin.adj, 
            cox.qrt, cox.qrt.adj, cox.linn, df1.hist, df.info2))

}

# get.coefs( var.fe = "fertn.log") # check
# get.coefs( var.fe = "PC1") # check

```


```{r}

# Run function over all five covariates

outcome.vars2 = c("fe.scale", "fertn.scale", "fesat.scale", "tibc.scale", "uibc.scale")
names(df)

outcome.vars3 = c("UMN_Iron_Baseline_FE",
                  "UMN_Iron_Baseline_FERTN",
                  "UMN_Iron_Baseline_FESAT",
                  "UMN_Iron_Baseline_TIBC",
                  "UMN_Iron_Baseline_UIBC")

outcome.vars = c("fe", "fertn.log", "fesat", 'PC1')
models1 = lapply(outcome.vars, get.coefs)

```


```{r}
# extract out sixth element from each list, the unadjusted model
model.un.list = lapply(models1, '[[', 6)

m1 = model.un.list[[1]]
m1$n

# extract out sevent element from each list, the adjusted model
model.adj.list = lapply(models1, '[[', 7)

m1a = model.adj.list[[1]]
m1a$n

```



```{r}
# extract out first element from each list, the coefficients to print off to table
coefs.list = lapply(models1, '[[', 1)  # This returns a list with only the first element, the extracted coef data frame

coefs.list[[2]]

cox.dat =  coefs.list %>% bind_rows() # source: https://stackoverflow.com/questions/2641653/pass-a-data-frame-column-name-to-a-function

n.row = nrow(cox.dat)
cox.dat$rows = rep(1:5, n.row/5)

tail(cox.dat, 20)
levels(cox.dat$adj)
cox.dat$adj = factor(cox.dat$adj, levels=c("Median",
                                           "Counts",
                                           "Ranges", 
                                           "No",
                                           "Yes"),
                     labels=c("Median",
                              "n",
                              "Ranges",
                              "Unadjusted",
                              "Adjusted$^a$"))
levels(cox.dat$adj)

head(cox.dat)
# Change data to match table format from Quintana-Pacheco

# take out the  Median(log trans)
cox.dat = cox.dat[!(cox.dat$adj=='Median(log trans)'),]

cox.dat.wide = dcast(cox.dat, cov.fe + adj ~ rows, value.var="coef")
cox.dat.wide

```


```{r}

# Get counts by case and menopause status 
# extract out ninth element from each list, the coefficients to print off to table
coefs.list = lapply(models1, '[[', 10)  # This returns a list with only the ninth element, the extracted coef data frame

head(coefs.list[[2]])

cox.dat2 =  coefs.list %>% bind_rows() # source: https://stackoverflow.com/questions/2641653/pass-a-data-frame-column-name-to-a-function
cox.dat2 = cox.dat2[complete.cases(cox.dat2$coef),]
head(cox.dat2)

cox.dat2.cts = cox.dat2[cox.dat2$adj=="Counts",]
cox.dat2.info = cox.dat2[!(cox.dat2$adj=="Counts"),]

n.row2 = nrow(cox.dat2.cts)
cox.dat2.cts$rows = rep(rep(1:4, each=2),4)
cox.dat2.info$rows = rep(rep(1:4, 8))

dim(cox.dat2.cts)
dim(cox.dat2.info)
cox.dat.both = rbind.data.frame(cox.dat2.cts, cox.dat2.info)

levels(cox.dat.both$adj)
cox.dat.both$adj = factor(cox.dat.both$adj, 
                      levels=c("Counts",
                               "Median",
                               "Ranges"),
                      labels=c("n",
                               "Median",
                               "Ranges"))
levels(cox.dat.both$adj)
head(cox.dat.both)

cox.dat.wide2 = dcast(cox.dat.both, 
                      cov.fe + adj + cases ~ rows, value.var="coef")
cox.dat.wide2


```


## Summary table


```{r, results='markup'}
# print off table

cox.dat.wide[cox.dat.wide=="NA"] <- "" # get rid of na
cox.dat.wide[is.na(cox.dat.wide)] <- "" # get rid of na

premenop = kable(cox.dat.wide[,-1],
               align='lllllc',
      caption = "Breast cancer risk associated with increasing levels of iron-related biomarkers for women with premenopausal person-time.",
      booktabs=T,
      col.names = c( "Biomarkers",
                     "Quartile 1",
                     "Quartile 2", 
                     "Quartile 3",
                     "Quartile 4",
                     " "),
      escape=F) %>%
  #mutate_all(linebreak) %>% # Source: http://haozhu233.github.io/kableExtra/best_practice_for_newline_in_latex_table.pdf
  add_header_above(c(" ",  "Quartile of iron-related biomarker" = 4, "Linear trend over quartiles$^c$" = 1), escape=F) %>%
  pack_rows("Iron ($\\\\mu$g/dL)", 1, 5, escape=F) %>%
  pack_rows("Ferritin$^b$ ($\\\\mu$g/dL)", 6, 10, escape=F) %>%
  pack_rows("Transferrin saturation (\\\\%)", 11, 15, escape=F) %>%
  pack_rows("First principal component", 16, 20) %>%
  column_spec(c(6), width = "4cm") %>% # NOTE: this has to come first to change row width?
#  pack_rows("TIBC", 13, 16) %>%
#  pack_rows("UIBC", 17, 20) %>% 
  # footnote(alphabet = c("Ferritin is log tranformed",
  #                       "Adjusted for alcohol, education, baseline BMI, baseline HRT (ever/never), baseline oral contraceptive use (any use? ever/never), age at menarche, age at first birth, early menopause (<=45 years)"), 
  #          general="Bold values indicate statistical significance at alpha = 0.05.",
  #          threeparttable=T) %>% # source: https://rdrr.io/cran/kableExtra/man/footnote.html
  footnote(alphabet = c("Adjusted for  baseline smoking, alcohol, education,  HRT, age at menarche, age at first birth, oral contraceptive use, and BMI.",
                        "log transformed",
                        "Iron covariate in quartile units"), 
           #general="Bold values indicate statistical significance at alpha = 0.05.",
           threeparttable=T) %>% # source: https://rdrr.io/cran/kableExtra/man/footnote.html
  # column_spec(1, width = "3.5cm") %>%
  # column_spec(2:3, width = "1cm") %>%
  # column_spec(4:7, width = "3cm") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"), font_size=10)
  
premenop.table.dat = cox.dat.wide
premenop.table.dat2 = cox.dat.wide2
save(premenop, premenop.table.dat, premenop.table.dat2,
     file="../sections/premenop.RData")
```



### Look at lower quartile of iron vs rest for the postmenopausal stratified analysis 

```{r, results='hide'}

# 7/9/2020 Additional analysis estimating breast cancer HR for lowest quartile vs 2nd - 4th quartile
# adapted from get.coef function

makedat = function(iron.variable){

  var.fe = iron.variable #"fe"
  # var.fe = "fe" # debug
  df.pc$var.fe = df.pc[,var.fe]
  
  summary(df.pc$var.fe); summary(df.pc$fe)
  
  df.e = df.pc[!(is.na(df.pc$var.fe)),] # need to remove missing for cch to work
  summary(df.e$var.fe)
  
  table(df.e$UMN_Iron_Subcohort)
  table(df.e$subcohort)
  table(df.e$event)
  with(df.e, table(subcohort, event), exclude=NULL)
  
  # get quartiles
  qrts = quantile(df.e$var.fe, c(0, 0.25, 0.5, 0.75, 1), na.rm=T)
  qrts2 = quantile(df.e$var.fe, c(0, 0.25, 1), na.rm=T)
  qrts; qrts2
  
  # Make a variable with cut points based on quartiles above
  df.e$fe.cutq = cut(df.e$var.fe, qrts, include.lowest = T, dig.lab=2)
  summary(df.e$fe.cutq)
  df.e$fe.cutq2 = cut(df.e$var.fe, qrts2, include.lowest = T, dig.lab=2)
  summary(df.e$fe.cutq2)
  
  # What is the median within those intervals? =====================
  dt = data.table(df.e)
  setkey(dt, fe.cutq)
  medians = dt[,list(median=median(fe, na.rm=T)), by=fe.cutq]
  medians = data.frame(medians[complete.cases(medians)])
  medians
  
  # get median of untransformed serum iron marker
  medians.orig = if(var.fe %in% c("fertn.log")) dt[,list(median=median(exp(fertn.log), na.rm=T)), by=fe.cutq] else dt[,list(median=median(var.fe, na.rm=T)), by=fe.cutq]
  
  medians.orig = data.frame(medians.orig[complete.cases(medians.orig)])
  medians.orig
  return(df.e)
}

df.fe=makedat("fe")

# 1) Cox ph with quartiles ==================================

sapply(df.fe[c("start.age", "c.age")], summary)
n.size=50884

# original analysis
vars1 = c("start.age", "c.age.alt", "event.alt", "fe.cutq")
summary(df.fe[vars1])

cox.qrt = cch(Surv(start.age, c.age.alt, event.alt) ~ fe.cutq , # + cluster(HH_PSID) # NOTE: clustering does not work
             data=df.fe[complete.cases(df.fe[vars1]),],
             subcoh = ~subcohort,
             id = ~ PSID,
             cohort.size=n.size)
cox.qrt
exp(coef(cox.qrt))
```

```{r, results='markup'}

summary(df.fe$fe.cutq2)
df.fe$fe.cutq2 = relevel(df.fe$fe.cutq2, ref="(70,2.8e+02]")

# additional analysis comparing lowest quartile to rest of group
table(df.fe$fe.cutq2)
vars2 = c("start.age", "c.age.alt", "event.alt", "fe.cutq2")

cox.qrt2 = cch(Surv(start.age, c.age.alt, event.alt) ~ fe.cutq2, # + cluster(HH_PSID) # NOTE: clustering does not work
             data=df.fe[complete.cases(df.fe[vars2]),],
             subcoh = ~subcohort,
             id = ~ PSID,
             cohort.size=n.size)

summary(cox.qrt2)
exp(coef(cox.qrt2))

get.ci(coef(summary(cox.qrt2)))

```

### Look at lower quartile of ferritin vs rest for the postmenopausal stratified analysis 

```{r, results='markup'}

df.fertn=makedat("fertn.log")

summary(df.fertn$fe.cutq2)
df.fertn$fe.cutq2 = relevel(df.fertn$fe.cutq2, ref="(3.1,7.4]") # pick the upper group as the referent
summary(df.fertn$fe.cutq2)
vars2 = c("start.age", "c.age.alt", "event.alt", "fe.cutq2")

# additional analysis comparing lowest quartile to rest of group
cox.qrt2 = cch(Surv(start.age, c.age.alt, event.alt) ~ fe.cutq2 , # + cluster(HH_PSID) # NOTE: clustering does not work
             data=df.fertn[complete.cases(df.fertn[vars2]),],
             subcoh = ~subcohort,
             id = ~ PSID,
             cohort.size=n.size)

cox.qrt2
exp(coef(cox.qrt2))

get.ci(coef(summary(cox.qrt2)))

```



### Look at lower quartile of transferrin saturation vs rest for the postmenopausal stratified analysis 

```{r, results='markup'}

df.fesat=makedat("fesat")

summary(df.fesat$fe.cutq2)
df.fesat$fe.cutq2 = relevel(df.fesat$fe.cutq2, ref="(21,90]") # pick the upper group as the referent
summary(df.fesat$fe.cutq2)

# additional analysis comparing lowest quartile to rest of group
cox.qrt2 = cch(Surv(start.age, c.age.alt, event.alt) ~ fe.cutq2 , # + cluster(HH_PSID) # NOTE: clustering does not work
             data=df.fesat[complete.cases(df.fesat[vars2]),],
             subcoh = ~subcohort,
             id = ~ PSID,
             cohort.size=n.size)

cox.qrt2
exp(coef(cox.qrt2))

get.ci(coef(summary(cox.qrt2)))

```



### Look at lower quartile of PC1 vs rest for the postmenopausal stratified analysis 

```{r, results='markup'}

df.pc=makedat("PC1")

summary(df.pc$fe.cutq2)
df.pc$fe.cutq2 = relevel(df.pc$fe.cutq2, ref="(-0.8,4.8]") # pick the upper group as the referent
summary(df.pc$fe.cutq2)

# additional analysis comparing lowest quartile to rest of group
cox.qrt2 = cch(Surv(start.age, c.age.alt, event.alt) ~ fe.cutq2 , # + cluster(HH_PSID) # NOTE: clustering does not work
             data=df.pc[complete.cases(df.pc[vars2]),],
             subcoh = ~subcohort,
             id = ~ PSID,
             cohort.size=n.size)

cox.qrt2
exp(coef(cox.qrt2))

get.ci(coef(summary(cox.qrt2)))

```


<!-- \blandscape -->

```{r, results='markup'}
premenop %>% landscape()
```

<!-- \elandscape -->


## Unadjusted models for quartiles

```{r, results='asis'}

list.unadj = lapply(models1, '[[', 2)  

for(i in list.unadj) print(i) 

```


## Adjusted models for quartiles

```{r, results='asis'}

list.unadj = lapply(models1, '[[', 3)  

for(i in list.unadj) print(i) 

```


## Unadjusted models for continuous variable

```{r, results='asis'}

list.unadj = lapply(models1, '[[', 4)  

for(i in list.unadj) print(i) 

```


## Adjusted models for continuous variable

```{r, results='asis'}

list.unadj = lapply(models1, '[[', 5)  

for(i in list.unadj) print(i) 

```


```{r}
# who is person wiht very low fe?
hist(df$UMN_Iron_Baseline_FE)
summary(df$UMN_Iron_Baseline_FE)
quantile(df$UMN_Iron_Baseline_FE, c(0, 0.01, 0.5, 0.99, 1), na.rm=T)

quantile(df$UMN_Iron_Baseline_FERTN, c(0, 0.15, 0.5, 0.99, 1), na.rm=T)

```

## spline plots


```{r}
# extract out eigth element from each list, a coxph with spline (no weights) -- make plot
spline.un.list = lapply(models1, '[[', 8)
#class(spline.un.list[[1]])
names(spline.un.list) = outcome.vars
names(spline.un.list)

outcome.vars

save(spline.un.list, file="splines.RData")

lapply(spline.un.list, function(x) {paste(names(x))
  termplot(x, term=1, se=TRUE, col.term=1, col.se=1)})


```

## Histograms of data with cutpoints as vertical lines

Check cut points relative to distribution of data.


```{r}

# extract out ninth element from each list, the coefficients to print off to table
df.list = lapply(models1, '[[', 9)  # This returns a list with only the ninth element, the extracted coef data frame

summary(df.list[[2]])


df.dat =  df.list %>% bind_rows() # source: https://stackoverflow.com/questions/2641653/pass-a-data-frame-column-name-to-a-function
warnings()

head(df.dat)
table(df.dat$cov.fe)
summary(df.dat[df.dat$cov.fe=="fesat",]$iron.var)
```

```{r}

table(df.dat$quart1)
qrt.breaks = with(df.dat, round(c(rbind(unique(quart1),
                            unique(quart2), 
                            unique(quart3))),1)); qrt.breaks
qrt.breaks1 = with(df.dat, round(unique(quart1)))

# Source: https://coolbutuseless.github.io/2019/03/07/custom-axis-breaks-on-facetted-ggplot/
count <- 0
breaks_fun <- function(x) {
  count <<- count + 1L
  switch(
    count,
    qrt.breaks[1:3],
    qrt.breaks[4:6],
    qrt.breaks[7:9],
    qrt.breaks[10:12]
  )
}


hist.premenop = ggplot(data=df.dat,
       aes(x=iron.var)) + 
  facet_wrap(cov.fe~., scale="free")+
  geom_histogram(fill="grey", bins=25) +
  theme_bw() +
  geom_vline(data= df.dat, aes(xintercept=quart1), color="green") +
  geom_vline(data= df.dat, aes(xintercept=quart2), color="green") +
  geom_vline(data= df.dat, aes(xintercept=quart3), color="green") +
  scale_x_continuous(breaks = breaks_fun) +
  labs(title="Histograms for premenopausal sample") #, limits = c(-5, NA)) 

hist.premenop + scale_x_continuous(breaks = breaks_fun)

# NOTE: have to re-run the breaks function every time you do the plot

count <- 0
breaks_fun <- function(x) {
  count <<- count + 1L
  switch(
    count,
    qrt.breaks[1:3],
    qrt.breaks[4:6],
    qrt.breaks[7:9],
    qrt.breaks[10:12]
  )
}


ggsave(hist.premenop + scale_x_continuous(breaks = breaks_fun),
       file="hist-premenop.png")

```

![](hist-premenop.png)


# Kaplan Meier plots



```{r, eval=T, include=F}

# Source: https://link.springer.com/article/10.1186/1471-2288-13-88
names(df.pc)

# get counting process for case cohort data
# ==========================================

cut.pts = unique(as.integer(c(df.pc$start.age, df.pc$c.age.alt))); cut.pts # get unique event times
class(cut.pts)
cut.pts = cut.pts[!is.na(order(cut.pts))]; cut.pts
cut.pts = cut.pts[!is.na(cut.pts)]; cut.pts # get rid of missing value

# make ceiling and floor ages for entry and exit ages into analysis.
# assume if they enter at a certain age they start at the floor (bottom integer) 
# and exit at the end of the year age interval
# the counting process data below will then be in year intervals
df.pc$floor.start.age = with(df.pc, floor(df.pc$start.age))
df.pc$ceil.exit.age = with(df.pc, ceiling(df.pc$c.age.alt))

vars.include = c("start.age", "c.age.alt",
                "event.alt", 
                "subcohort")

ccdat = survSplit(Surv(floor.start.age, ceil.exit.age, event.alt) ~ ., 
                  data=df.pc[complete.cases(df.pc[vars.include]),], 
                  na.action=na.pass,
                  cut=cut.pts, #as.numeric(ct.pts),
                  start="tstart",
                  end="tstop", event="event",
                  id="id")

head(ccdat[c("PSID", "tstart", "tstop", "start.age", "c.age.alt", "event", "id")], 20)
head(df.pc[c("PSID", "start.age", "c.age.alt", "event")])
dim(ccdat)

# Source: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-13-88
# for people not in subcohort, 
# "The pseudolikelihood function can be readily constructed using available statistical software by adopting a counting process to describe the event time (i.e., each subject’s time to event process is described by a series of start and stop intervals) [22]. Note that an event that occurs outside the subcohort is assigned a start time immediately before the moment of the event so that this event does not contribute data to any other risk sets."

# for anyone who is subcohort=0 (no) remove all time intervals except last one (before event)
ccdat$remove.row = with(ccdat, ifelse(subcohort==0 & !(event==1), 1, 0) )
ccdat.rev = ccdat[ccdat$remove.row==0,]
dim(ccdat.rev)
dim(ccdat)

head(ccdat[ccdat$subcohort==0,]$PSID) # some people not in subcohort

# check
vars.include = c("PSID", "start.age", "tstart",
                 "c.age.alt", "tstop",
                "event",
                "subcohort")

#head(ccdat[ccdat$PSID=="00224_100315",vars.include])
#head(ccdat.rev[ccdat$PSID=="00224_100315",vars.include])

# make start time immediately before stop time for non-subcohort
ccdat.rev$tstart.rev = with(ccdat.rev, ifelse(subcohort==0, tstop-0.0001, tstart))
# check
#head(ccdat.rev[ccdat$PSID=="00224_100315",c(vars.include, "tstart.rev")])

# Put cases in subcohort in sample twice. once for time before event and again for time at event: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2216006/
# how many people with event in subcohort?



```


```{r}

# Make a function to loop over each strata to get KM curves

get.strata = function(strata, ironvar, ironvar2){
  
    # strata="(3.714,4.331]";  ironvar = "fertn.cutq"; ironvar2="fertn.log" # debug
    # strata="(1.017,4.847]"; ironvar = "pc1.qrt"; ironvar2="PC1" # debug
    ccdat.rev$iron.var = ccdat.rev[,ironvar]
    ccdat.rev$iron.var2 = ccdat.rev[,ironvar2]
    head(ccdat.rev$iron.var2)
    dat = ccdat.rev[ccdat.rev$iron.var==strata,]
    
    
    sfit1 = survfit(Surv(tstart.rev, tstop, event) ~ 1, 
                   data = dat)
    summary(sfit1)
    
    
    sest1 = sfit1$surv[sfit1$n.event>0]
    sest1
    
    ecnt1 = sfit1$n.event[sfit1$n.event>0]
    ecnt1
    
    
    km.times1 = sfit1$time[sfit1$n.event>0]
    km.times1
    
    # subcohort of size m and a cohort of size n
    m = dim(df.pc[df.pc$subcohort==1,])[1] # 1005
    n = 50884
      
    km1 = rep(sest1^(m/n), ecnt1) 
    head(km1)
    length(km1) #499
    
    # plot km data?
    km.times2 = rep(km.times1, ecnt1)
    
    km.data = data.frame(km=km1, 
                         time=km.times2,
                         strata=strata)
    
    # make a data set with all time points for km plot
    # ================================================
    sfit1.40 = update(sfit1, data=dat[dat$tstart.rev>=40,])
    
    km.times0 = sfit1.40$time[sfit1$n.event==0]; km.times0
    km.times1 = sfit1.40$time[sfit1$n.event>0]; km.times1
    km.surv1 = sfit1.40$surv[sfit1$n.event>0]^(m/n)

    if(km.times0[1]<km.times1[1]){
      km.data.both = data.frame(km=c(1, km.surv1),
                              time = c(km.times0[1], km.times1),
                              strata=strata)
  
      km.plot.dat = km.data.both[order(km.data.both$time),]
    } else {
      km.data.both = data.frame(km = c(1, km.surv1),
                                time = c(35, km.times1),
                                strata=strata)
      km.plot.dat = km.data.both[order(km.data.both$time),]
    }
    km.plot.dat

    # compute schoenfeld residuals
    # ==========================================

    coxfit = coxph(Surv(tstart.rev, tstop, event) ~ iron.var2 + cluster(id), 
                   data = dat, method = "breslow", robust = T, id=id)
    
    # correlation test with time
    # ===================================================
    
    sresid = resid(coxfit, type = "schoenfeld")
    length(sort(dat$tstop[dat$event==1]))
    test.time = cor.test(sort(dat$tstop[dat$event==1]), sresid, method = "pearson")$p.value 

    
    # correlation test with rank order of event time 
    # =================================================
    
    test.time.rank = cor.test(rank(sort(dat$tstop[dat$event==1])),
             sresid,
             method = "pearson")$p.value 
        
    # correlation test with KM estimates
    # ===============================================
    test.km = cor.test(km1, sresid, method = "pearson")$p.value 
    
    p.vals = data.frame(test.time=test.time, 
                        test.time.rank=test.time.rank, 
                        test.km=test.km,
                        strata=strata )

    
    return(list(km.data, p.vals, km.plot.dat))
}
```

```{r}

# run km strata function over all four levels of strata for fertn.log
names.fertn = levels(factor(ccdat.rev$fertn.cutq)); names.fertn
ironvar2="fertn.log"
list.fertn.km = lapply(names.fertn, get.strata, ironvar="fertn.cutq", ironvar2=ironvar2)

# extract out first item of list of list from function above
df.fertn.km. = sapply(list.fertn.km, "[", 3) 
# append all km data into one data frame for plotting
df.fertn.km = do.call(rbind.data.frame, df.fertn.km.)
dim(df.fertn.km)
summary(df.fertn.km)
head(df.fertn.km)

km.plot = ggplot(data=df.fertn.km,
       aes(x=time, y=km, colour=strata)) + 
  labs(title=ironvar2)+
  geom_step() +
  xlim(40,55) + ylim(0.97,1) +
  theme_bw()
km.plot

# extract out p-vals testing for violation of ph
pval. = sapply(list.fertn.km, "[", 2) 
# append all pvals
pval = do.call(rbind.data.frame, pval.)
pval$min.p = do.call(pmin, pval[,c("test.time", "test.time.rank", "test.km")])
pval

# save for reviewer-tables.Rmd
save(pval, km.plot, file="prem-km-fertn.Rmd")

```


```{r}

# run km strata function over all four levels of strata for fe

names.fe = levels(factor(ccdat.rev$fe.qrt)); names.fe
ironvar2="fe"
list.fe.km = lapply(names.fe, get.strata, ironvar="fe.qrt", ironvar2=ironvar2)

# extract out first item of list of list from function above
df.fe.km. = sapply(list.fe.km, "[", 3) 
# append all km data into one data frame for plotting
df.fe.km = do.call(rbind.data.frame, df.fe.km.)
dim(df.fe.km)
summary(df.fe.km)

km.plot = ggplot(data=df.fe.km,
       aes(x=time, y=km, colour=strata)) + 
  labs(title=ironvar2)+
  geom_step() +
  xlim(40,55) + ylim(0.97,1) +
  theme_bw()
km.plot

# extract out p-vals testing for violation of ph
pval. = sapply(list.fe.km, "[", 2) 
# append all pvals
pval = do.call(rbind.data.frame, pval.)
pval$min.p = do.call(pmin, pval[,c("test.time", "test.time.rank", "test.km")])
pval

# save for reviewer-tables.Rmd
save(pval, km.plot, file="prem-km-fe.Rmd")

```


```{r}

# run km strata function over all four levels of strata for fesat

names.fesat = levels(factor(ccdat.rev$fesat.qrt)); names.fesat
ironvar2="fesat"
list.fesat.km = lapply(names.fesat, get.strata, ironvar="fesat.qrt", ironvar2=ironvar2)

# extract out first item of list of list from function above
df.fesat.km. = sapply(list.fesat.km, "[", 3) 
# append all km data into one data frame for plotting
df.fesat.km = do.call(rbind.data.frame, df.fesat.km.)
dim(df.fesat.km)
summary(df.fesat.km)

km.plot = ggplot(data=df.fesat.km,
       aes(x=time, y=km, colour=strata)) + 
  labs(title=ironvar2)+
  geom_step() +
  xlim(40,55) + ylim(0.97,1) +
  theme_bw()
km.plot

# extract out p-vals testing for violation of ph
pval. = sapply(list.fesat.km, "[", 2) 
# append all pvals
pval = do.call(rbind.data.frame, pval.)
pval$min.p = do.call(pmin, pval[,c("test.time", "test.time.rank", "test.km")])
pval

# save for reviewer-tables.Rmd
save(pval, km.plot, file="prem-km-fesat.Rmd")

```



```{r}

# run km strata function over all four levels of strata for pc1

names.pc1 = levels(factor(ccdat.rev$pc1.qrt)); names.pc1
ironvar2="PC1"
list.pc1.km = lapply(names.pc1, get.strata, ironvar="pc1.qrt", ironvar2=ironvar2)

# extract out first item of list of list from function above
df.pc1.km. = sapply(list.pc1.km, "[", 3) 
# append all km data into one data frame for plotting
df.pc1.km = do.call(rbind.data.frame, df.pc1.km.)
dim(df.pc1.km)
summary(df.pc1.km)

km.plot = ggplot(data=df.pc1.km,
       aes(x=time, y=km, colour=strata)) + 
  labs(title=ironvar2)+
  geom_step() +
  xlim(40,55) + ylim(0.97,1) +
  theme_bw()
km.plot

# extract out p-vals testing for violation of ph
pval. = sapply(list.pc1.km, "[", 2) 
# append all pvals
pval = do.call(rbind.data.frame, pval.)
pval$min.p = do.call(pmin, pval[,c("test.time", "test.time.rank", "test.km")])
pval

# save for reviewer-tables.Rmd
save(pval, km.plot, file="prem-km-pc1.Rmd")

```



```{r, include=F, eval=F}
# Look at km with the counting process data set from 
# Source: https://link.springer.com/article/10.1186/1471-2288-13-88
# above.

# these are incorrect. see above

# Source: https://github.com/kassambara/survminer/issues/67
fit = survfit(Surv(start.age, c.age.alt, event) ~ fesat.qrt ,
             data=ccdat.rev)

ggsurvplot(fit,  palette = "Dark2", 
           censor=T,
           xlim=c(35,60),
           ylim=c(0.5,1),
           break.time.by=5)


fit = survfit(Surv(start.age, c.age.alt, event) ~ fe.qrt ,
             data=ccdat.rev)

ggsurvplot(fit,  palette = "Dark2", 
           censor=T,
           xlim=c(35,60),
           ylim=c(0.5,1),
           break.time.by=5)

# fertn.qrt
names(ccdat.rev)
summary(ccdat.rev$fertn.cutq)

fit = survfit(Surv(start.age, c.age.alt, event) ~ fertn.cutq ,
             data=ccdat.rev)

ggsurvplot(fit,  palette = "Dark2", 
           censor=T,
           xlim=c(35,60),
           ylim=c(0.5,1),
           break.time.by=5)

```

